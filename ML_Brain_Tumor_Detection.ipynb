{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b375536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a74ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías de Scikit-learn para preprocesamiento y métricas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b79ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced-learn para manejar desbalance de clases\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b09afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 14:22:18.157078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748456538.265929    8196 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748456538.298553    8196 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748456538.518374    8196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748456538.518414    8196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748456538.518418    8196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748456538.518422    8196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-28 14:22:18.541799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Componentes de TensorFlow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, callbacks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50 # El modelo base que usaremos\n",
    "from tensorflow.keras.applications.resnet import preprocess_input # Función de preprocesamiento específica para ResNet\n",
    "from tensorflow.keras.metrics import AUC # Métrica de Área Bajo la Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf4066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1748456545.942904    8196 gpu_device.cc:2430] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 5.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6257bc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'keras.src.models.model',\n",
       "              '__doc__': 'A model grouping layers into an object with training/inference features.\\n\\n    There are three ways to instantiate a `Model`:\\n\\n    ## With the \"Functional API\"\\n\\n    You start from `Input`,\\n    you chain layer calls to specify the model\\'s forward pass,\\n    and finally, you create your model from inputs and outputs:\\n\\n    ```python\\n    inputs = keras.Input(shape=(37,))\\n    x = keras.layers.Dense(32, activation=\"relu\")(inputs)\\n    outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\\n    model = keras.Model(inputs=inputs, outputs=outputs)\\n    ```\\n\\n    Note: Only dicts, lists, and tuples of input tensors are supported. Nested\\n    inputs are not supported (e.g. lists of list or dicts of dict).\\n\\n    A new Functional API model can also be created by using the\\n    intermediate tensors. This enables you to quickly extract sub-components\\n    of the model.\\n\\n    Example:\\n\\n    ```python\\n    inputs = keras.Input(shape=(None, None, 3))\\n    processed = keras.layers.RandomCrop(width=128, height=128)(inputs)\\n    conv = keras.layers.Conv2D(filters=32, kernel_size=3)(processed)\\n    pooling = keras.layers.GlobalAveragePooling2D()(conv)\\n    feature = keras.layers.Dense(10)(pooling)\\n\\n    full_model = keras.Model(inputs, feature)\\n    backbone = keras.Model(processed, conv)\\n    activations = keras.Model(conv, feature)\\n    ```\\n\\n    Note that the `backbone` and `activations` models are not\\n    created with `keras.Input` objects, but with the tensors that originate\\n    from `keras.Input` objects. Under the hood, the layers and weights will\\n    be shared across these models, so that user can train the `full_model`, and\\n    use `backbone` or `activations` to do feature extraction.\\n    The inputs and outputs of the model can be nested structures of tensors as\\n    well, and the created models are standard Functional API models that support\\n    all the existing APIs.\\n\\n    ## By subclassing the `Model` class\\n\\n    In that case, you should define your\\n    layers in `__init__()` and you should implement the model\\'s forward pass\\n    in `call()`.\\n\\n    ```python\\n    class MyModel(keras.Model):\\n        def __init__(self):\\n            super().__init__()\\n            self.dense1 = keras.layers.Dense(32, activation=\"relu\")\\n            self.dense2 = keras.layers.Dense(5, activation=\"softmax\")\\n\\n        def call(self, inputs):\\n            x = self.dense1(inputs)\\n            return self.dense2(x)\\n\\n    model = MyModel()\\n    ```\\n\\n    If you subclass `Model`, you can optionally have\\n    a `training` argument (boolean) in `call()`, which you can use to specify\\n    a different behavior in training and inference:\\n\\n    ```python\\n    class MyModel(keras.Model):\\n        def __init__(self):\\n            super().__init__()\\n            self.dense1 = keras.layers.Dense(32, activation=\"relu\")\\n            self.dense2 = keras.layers.Dense(5, activation=\"softmax\")\\n            self.dropout = keras.layers.Dropout(0.5)\\n\\n        def call(self, inputs, training=False):\\n            x = self.dense1(inputs)\\n            x = self.dropout(x, training=training)\\n            return self.dense2(x)\\n\\n    model = MyModel()\\n    ```\\n\\n    Once the model is created, you can config the model with losses and metrics\\n    with `model.compile()`, train the model with `model.fit()`, or use the model\\n    to do prediction with `model.predict()`.\\n\\n    ## With the `Sequential` class\\n\\n    In addition, `keras.Sequential` is a special case of model where\\n    the model is purely a stack of single-input, single-output layers.\\n\\n    ```python\\n    model = keras.Sequential([\\n        keras.Input(shape=(None, None, 3)),\\n        keras.layers.Conv2D(filters=32, kernel_size=3),\\n    ])\\n    ```\\n    ',\n",
       "              '__new__': <staticmethod(<function Model.__new__ at 0x7f2c4d0554e0>)>,\n",
       "              '__init__': <function keras.src.models.model.Model.__init__(self, *args, **kwargs)>,\n",
       "              'call': <function keras.src.models.model.Model.call(self, *args, **kwargs)>,\n",
       "              'layers': <property at 0x7f2c4d061cb0>,\n",
       "              'get_layer': <function keras.src.models.model.Model.get_layer(self, name=None, index=None)>,\n",
       "              'summary': <function keras.src.models.model.Model.summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)>,\n",
       "              'save': <function keras.src.models.model.Model.save(self, filepath, overwrite=True, zipped=None, **kwargs)>,\n",
       "              'save_weights': <function keras.src.models.model.Model.save_weights(self, filepath, overwrite=True, max_shard_size=None)>,\n",
       "              'load_weights': <function keras.src.models.model.Model.load_weights(self, filepath, skip_mismatch=False, **kwargs)>,\n",
       "              'quantize': <function keras.src.models.model.Model.quantize(self, mode, **kwargs)>,\n",
       "              'build_from_config': <function keras.src.models.model.Model.build_from_config(self, config)>,\n",
       "              'to_json': <function keras.src.models.model.Model.to_json(self, **kwargs)>,\n",
       "              'export': <function keras.src.models.model.Model.export(self, filepath, format='tf_saved_model', verbose=None, input_signature=None, **kwargs)>,\n",
       "              'from_config': <classmethod(<function Model.from_config at 0x7f2c4d0a3600>)>,\n",
       "              '_get_variable_map': <function keras.src.models.model.Model._get_variable_map(self)>,\n",
       "              'get_state_tree': <function keras.src.models.model.Model.get_state_tree(self, value_format='backend_tensor')>,\n",
       "              '_create_nested_dict': <function keras.src.models.model.Model._create_nested_dict(self, variables, value_format)>,\n",
       "              'set_state_tree': <function keras.src.models.model.Model.set_state_tree(self, state_tree)>,\n",
       "              '_assign_variable_values': <function keras.src.models.model.Model._assign_variable_values(self, variables, path_value_dict)>,\n",
       "              '_flatten_nested_dict': <function keras.src.models.model.Model._flatten_nested_dict(self, nested_dict)>,\n",
       "              '_api_export_path': ['keras.Model', 'keras.models.Model'],\n",
       "              '_api_export_symbol_id': 1154206448})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bf793b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para la visualización y logs de TensorFlow\n",
    "sns.set_style(\"whitegrid\") # Estilo para los gráficos de Seaborn\n",
    "tf.get_logger().setLevel('ERROR') # Suprime mensajes informativos de TensorFlow, mostrando solo errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed005045",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"images\"  # Directorio raíz donde se encuentran las carpetas de categorías\n",
    "categories = [\"Healthy\", \"Tumor\"] # Nombres de las subcarpetas y nuestras clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8381d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = []  # Lista para almacenar las rutas a cada imagen\n",
    "labels = []       # Lista para almacenar la etiqueta de cada imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94ef45b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame inicial con rutas de imágenes y etiquetas:\n",
      "                            image_path    label\n",
      "0  images/Healthy/mri_healthy (17).jpg  Healthy\n",
      "1  images/Healthy/mri_healthy (16).jpg  Healthy\n",
      "2  images/Healthy/mri_healthy (36).jpg  Healthy\n",
      "3   images/Healthy/mri_healthy (8).jpg  Healthy\n",
      "4  images/Healthy/mri_healthy (11).jpg  Healthy\n",
      "\n",
      "Distribución de clases inicial:\n",
      "label\n",
      "Healthy    53\n",
      "Tumor      50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre cada categoría definida\n",
    "image_paths=[]\n",
    "labels=[]\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_path, category) # Construir la ruta a la carpeta de la categoría\n",
    "    if os.path.isdir(category_path):\n",
    "        # Iterar sobre cada archivo de imagen dentro de la carpeta de la categoría\n",
    "        for image_name in os.listdir(category_path):\n",
    "            image_path = os.path.join(category_path, image_name) # Ruta completa a la imagen\n",
    "            image_paths.append(image_path) # Añadir la ruta de la imagen a la lista\n",
    "            labels.append(category)        # Añadir la etiqueta (nombre de la categoría) a la lista\n",
    "    else:\n",
    "        print(f\"Advertencia: El directorio para la categoría '{category}' no fue encontrado en '{category_path}'\")\n",
    "\n",
    "# Crear un DataFrame de Pandas para almacenar las rutas de las imágenes y sus etiquetas\n",
    "df = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame y la distribución de clases\n",
    "print(\"DataFrame inicial con rutas de imágenes y etiquetas:\")\n",
    "print(df.head())\n",
    "print(\"\\nDistribución de clases inicial:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e73d2397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/Healthy/mri_healthy (17).jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/Healthy/mri_healthy (16).jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/Healthy/mri_healthy (36).jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/Healthy/mri_healthy (8).jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/Healthy/mri_healthy (11).jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>images/Tumor/glioma (30).jpg</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>images/Tumor/glioma (48).jpg</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>images/Tumor/glioma (27).jpg</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>images/Tumor/glioma (31).jpg</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>images/Tumor/glioma (18).jpg</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image_path    label\n",
       "0    images/Healthy/mri_healthy (17).jpg  Healthy\n",
       "1    images/Healthy/mri_healthy (16).jpg  Healthy\n",
       "2    images/Healthy/mri_healthy (36).jpg  Healthy\n",
       "3     images/Healthy/mri_healthy (8).jpg  Healthy\n",
       "4    images/Healthy/mri_healthy (11).jpg  Healthy\n",
       "..                                   ...      ...\n",
       "98          images/Tumor/glioma (30).jpg    Tumor\n",
       "99          images/Tumor/glioma (48).jpg    Tumor\n",
       "100         images/Tumor/glioma (27).jpg    Tumor\n",
       "101         images/Tumor/glioma (31).jpg    Tumor\n",
       "102         images/Tumor/glioma (18).jpg    Tumor\n",
       "\n",
       "[103 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364db2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef846a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
