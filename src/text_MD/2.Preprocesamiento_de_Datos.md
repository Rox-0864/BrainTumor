Una vez cargados los datos, el siguiente paso crucial es el preprocesamiento. Esta etapa prepara las imágenes y sus etiquetas para que puedan ser utilizadas eficientemente por el modelo de Deep Learning. Incluye la codificación de etiquetas, el manejo de desbalance de clases, la división de los datos en conjuntos de entrenamiento, validación y prueba, y finalmente, la creación de generadores de imágenes que alimentarán al modelo durante el entrenamiento y la evaluación.

## 2.1 Codificación de Etiquetas
Los modelos de Machine Learning y Deep Learning generalmente trabajan con datos numéricos. Por lo tanto, nuestras etiquetas categóricas (ej. "Healthy", "Tumor") deben ser convertidas a un formato numérico. Utilizamos `LabelEncoder` de Scikit-learn para esta tarea.

```python
# %% Preprocesamiento
# Codificación de etiquetas
label_encoder = LabelEncoder()
# Se crea una nueva columna 'category_encoded' con las etiquetas numéricas (ej. 0 para Healthy, 1 para Tumor)
df['category_encoded'] = label_encoder.fit_transform(df['label'])

print("DataFrame después de la codificación de etiquetas:")
print(df.head())
print(f"Clases codificadas: {label_encoder.classes_} -> {label_encoder.transform(label_encoder.classes_)}")
```

## 2.2 División de Datos
Antes de cualquier técnica de remuestreo (como el sobremuestreo), es fundamental dividir nuestros datos en conjuntos de entrenamiento, validación y prueba. Esto asegura que la validación y la prueba se realicen sobre datos que el modelo no ha visto de ninguna forma (ni siquiera versiones duplicadas), previniendo así la fuga de datos (data leakage).
Dividimos el DataFrame df (que contiene las rutas de imágenes y las etiquetas codificadas originales) de la siguiente manera:
- 80% para entrenamiento.
- 10% para validación.
- 10% para prueba.
Se utiliza la estratificación (stratify) para mantener una proporción similar de clases en cada conjunto.

```python
# Primero, dividir en entrenamiento (80%) y un conjunto temporal (20% para validación + prueba)
X_train_original, X_temp, y_train_original, y_temp = train_test_split(
    df[['image_path']],  # Características (rutas de imagen como DataFrame)
    df['category_encoded'], # Etiquetas numéricas
    train_size=0.8,         # 80% para entrenamiento
    shuffle=True,           # Mezclar los datos antes de dividir
    random_state=42,        # Para reproducibilidad
    stratify=df['category_encoded'] # Asegurar proporciones de clase similares en la división
)

# Luego, dividir el conjunto temporal en validación (50% de temp -> 10% del total)
X_valid, X_test, y_valid, y_test = train_test_split(
    X_temp,                 # DataFrame con rutas de imagen del conjunto temporal
    y_temp,                 # Etiquetas del conjunto temporal
    test_size=0.5,          # 50% de X_temp para el conjunto de prueba (el resto para validación)
    shuffle=True,
    random_state=42,
    stratify=y_temp         # Estratificar sobre las etiquetas del conjunto temporal
)
```

## 2.3 Sobremuestreo del Conjunto de Entrenamiento
Para abordar el posible desbalance de clases en el conjunto de datos (donde una clase podría tener significativamente más muestras que otra), se aplica la técnica de sobremuestreo aleatorio (RandomOverSampler). Esta técnica se aplica exclusivamente al conjunto de entrenamiento (X_train_original, y_train_original). RandomOverSampler duplica aleatoriamente instancias de la clase minoritaria hasta que las clases en el conjunto de entrenamiento estén balanceadas.

```python
ros = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train_original, y_train_original)
```

## 2.4 Creación de DataFrames para los Generadores
Con los datos ya divididos (y el conjunto de entrenamiento sobremuestreado), se crean nuevos DataFrames (train_df, valid_df, test_df) que serán utilizados por los generadores de imágenes de Keras. Las etiquetas codificadas se convierten a tipo string, una práctica común para flow_from_dataframe.

```python
# train_df utilizará los datos de entrenamiento sobremuestreados.
train_df = pd.DataFrame(X_train_resampled, columns=['image_path'])
train_df['category_encoded'] = y_train_resampled.astype(str)

# valid_df y test_df utilizan los datos originales de validación y prueba, sin sobremuestreo.
valid_df = pd.DataFrame(X_valid, columns=['image_path'])
valid_df['category_encoded'] = y_valid.astype(str)

test_df = pd.DataFrame(X_test, columns=['image_path'])
test_df['category_encoded'] = y_test.astype(str)
```

## 2.5 Configuración de Generadores de Datos para ResNet
Se utiliza *ImageDataGenerator* de Keras para cargar imágenes eficientemente desde el disco y aplicar transformaciones en tiempo real.
- **batch_size:** Define el número de imágenes procesadas en cada lote durante el entrenamiento/evaluación.
- **img_size:** Establece el tamaño al que todas las imágenes serán redimensionadas (224x224 píxeles, el estándar para ResNet50).

## 2.6 Aumentación de Datos para Entrenamiento (train_datagen)
Para el conjunto de entrenamiento, se configura un ImageDataGenerator (train_datagen) que aplica diversas técnicas de aumentación de datos (rotaciones, desplazamientos, zoom, etc.). Esto incrementa artificialmente la diversidad del conjunto de entrenamiento, ayudando al modelo a generalizar mejor y reducir el sobreajuste. También se incluye la función preprocess_input, que es el preprocesamiento específico requerido por los modelos ResNet pre-entrenados en ImageNet.

```python
# %% Generadores de datos para ResNet
batch_size = 32
img_size = (224, 224)  # ResNet requiere 224x224

# Data augmentation para entrenamiento
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Preprocesamiento específico de ResNet
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
```

## 2.7 Preprocesamiento para Validación y Prueba (test_datagen)
Para los conjuntos de validación y prueba, se crea otro ImageDataGenerator (test_datagen). Este generador no aplica aumentación de datos. Únicamente realiza el preprocess_input necesario para ResNet, asegurando que la evaluación del modelo se realice sobre datos "limpios" y consistentes.

```python
# Solo preprocesamiento para validación y prueba
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
```

## 2.8 Creación de los Flujos de Datos (flow_from_dataframe)
Se utiliza el método *flow_from_dataframe* de los ImageDataGenerator para crear los iteradores (train_gen, valid_gen, test_gen) que leerán las imágenes desde las rutas especificadas en los DataFrames (train_df, valid_df, test_df) y las alimentarán al modelo por lotes.

```python
# Generador para el conjunto de entrenamiento
train_gen = train_datagen.flow_from_dataframe(
    train_df,                   # DataFrame con datos de entrenamiento (sobremuestreados)
    x_col='image_path',         # Columna con las rutas de las imágenes
    y_col='category_encoded',   # Columna con las etiquetas codificadas (como string)
    target_size=img_size,       # Tamaño al que se redimensionarán las imágenes
    class_mode='binary',        # Para clasificación binaria
    color_mode='rgb',           # Cargar imágenes en color
    shuffle=True,               # Mezclar los datos de entrenamiento en cada época
    batch_size=batch_size
)

# Generador para el conjunto de validación
valid_gen = test_datagen.flow_from_dataframe(
    valid_df,                   # DataFrame con datos de validación (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=True,               # Mezclar datos de validación (opcional, pero True en el script)
    batch_size=batch_size
)

# Generador para el conjunto de prueba
test_gen = test_datagen.flow_from_dataframe(
    test_df,                    # DataFrame con datos de prueba (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=False,              # IMPORTANTE: No mezclar el conjunto de prueba
    batch_size=batch_size
)
```

Con estos pasos, los datos están completamente preparados: las etiquetas están codificadas, el desbalance de clases en el entrenamiento ha sido mitigado mediante sobremuestreo, los datos están divididos correctamente, y los generadores están listos para alimentar eficientemente las imágenes (con aumentación para el entrenamiento) al modelo ResNet50.
