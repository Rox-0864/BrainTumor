# Bloque 1: Configuraci贸n Inicial y Carga de Datos 

Comenzamos importando las herramientas necesarias. Aunque se utilizan varias librer铆as para el an谩lisis, visualizaci贸n y m茅tricas, **TensorFlow** (junto con su API Keras) es el pilar para la construcci贸n y entrenamiento de nuestro modelo de Deep Learning. Tambi茅n se emplean librer铆as como Pandas para la manipulaci贸n de datos y OS para interactuar con el sistema de archivos.


##1.1 Importaci贸n de Librer铆as Esenciales

!python --version

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

# Librer铆as de Scikit-learn para preprocesamiento y m茅tricas
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc

# Imbalanced-learn para manejar desbalance de clases
#from imblearn.over_sampling import RandomOverSampler

# Componentes de TensorFlow y Keras
import tensorflow as tf
tf.get_logger().setLevel('ERROR')# Suprime mensajes informativos de TensorFlow, mostrando solo errores
tf.autograph.set_verbosity(0)
from tensorflow import keras
from keras import layers, Model, callbacks
from keras.api.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.api.applications import ResNet50 # El modelo base que usaremos
from keras.api.applications.resnet import preprocess_input # Funci贸n de preprocesamiento espec铆fica para ResNet
from keras.api.metrics import AUC # M茅trica de rea Bajo la Curva ROC

# Configuraci贸n para la visualizaci贸n y logs de TensorFlow
sns.set_style("whitegrid") # Estilo para los gr谩ficos de Seaborn


tf.__version__

from google.colab import drive
drive.mount('/content/drive')


## 1.2 Definici贸n de Rutas y Carga de Datos
Las im谩genes se encuentran almacenadas en un directorio local, estructurado con subcarpetas que representan cada una de las clases (categor铆as) de nuestro problema de clasificaci贸n.
- **base_path:** Es el directorio ra铆z que contiene las subcarpetas de las categor铆as.
- **categories:** Una lista con los nombres de las subcarpetas, que corresponden a nuestras etiquetas de clase (ej. "Healthy", "Tumor").

base_path = "/content/drive/MyDrive/Brain_tumor_detection/image"  # Directorio ra铆z donde se encuentran las carpetas de categor铆as
categories = ["Healthy", "Tumor"] # Nombres de las subcarpetas y nuestras clases

image_paths = []  # Lista para almacenar las rutas a cada imagen
labels = []       # Lista para almacenar la etiqueta de cada imagen

# Iterar sobre cada categor铆a definida
for category in categories:
    category_path = os.path.join(base_path, category) # Construir la ruta a la carpeta de la categor铆a
    if os.path.isdir(category_path):
        # Iterar sobre cada archivo de imagen dentro de la carpeta de la categor铆a
        for image_name in os.listdir(category_path):
            image_path = os.path.join(category_path, image_name) # Ruta completa a la imagen
            image_paths.append(image_path) # A帽adir la ruta de la imagen a la lista
            labels.append(category)        # A帽adir la etiqueta (nombre de la categor铆a) a la lista
    else:
        print(f"Advertencia: El directorio para la categor铆a '{category}' no fue encontrado en '{category_path}'")


# Crear un DataFrame de Pandas para almacenar las rutas de las im谩genes y sus etiquetas
df = pd.DataFrame({"image_path": image_paths, "label": labels})
# Mostrar las primeras filas del DataFrame y la distribuci贸n de clases
print("DataFrame inicial con rutas de im谩genes y etiquetas:")
print(df.head())
print("\nDistribuci贸n de clases inicial:")
print(df['label'].value_counts())

# Bloque 2 : Preprocesamiento_de_Datos

## 2.1 Codificaci贸n de Etiquetas

# %% Preprocesamiento
# Codificaci贸n de etiquetas
label_encoder = LabelEncoder()
# Se crea una nueva columna 'category_encoded' con las etiquetas num茅ricas (ej. 0 para Healthy, 1 para Tumor)
df['category_encoded'] = label_encoder.fit_transform(df['label'])

print("DataFrame despu茅s de la codificaci贸n de etiquetas:")
print(df.head())
print(f"Clases codificadas: {label_encoder.classes_} -> {label_encoder.transform(label_encoder.classes_)}")

## 2.2 Divisi贸n de Datos

# Primero, dividir en entrenamiento (80%) y un conjunto temporal (20% para validaci贸n + prueba)
X_train_original, X_temp, y_train_original, y_temp = train_test_split(
    df[['image_path']],  # Caracter铆sticas (rutas de imagen como DataFrame)
    df['category_encoded'], # Etiquetas num茅ricas
    train_size=0.8,         # 80% para entrenamiento
    shuffle=True,           # Mezclar los datos antes de dividir
    random_state=42,        # Para reproducibilidad
    stratify=df['category_encoded'] # Asegurar proporciones de clase similares en la divisi贸n
)

# Luego, dividir el conjunto temporal en validaci贸n (50% de temp -> 10% del total)
X_valid, X_test, y_valid, y_test = train_test_split(
    X_temp,                 # DataFrame con rutas de imagen del conjunto temporal
    y_temp,                 # Etiquetas del conjunto temporal
    test_size=0.5,          # 50% de X_temp para el conjunto de prueba (el resto para validaci贸n)
    shuffle=True,
    random_state=42,
    stratify=y_temp         # Estratificar sobre las etiquetas del conjunto temporal
)

## 2.3 Creaci贸n de DataFrames para los Generadores

# train_df utilizar谩 los datos de entrenamiento sobremuestreados.
train_df = pd.DataFrame(X_train_original, columns=['image_path'])
train_df['category_encoded'] = y_train_original.astype(str)

# valid_df y test_df utilizan los datos originales de validaci贸n y prueba, sin sobremuestreo.
valid_df = pd.DataFrame(X_valid, columns=['image_path'])
valid_df['category_encoded'] = y_valid.astype(str)

test_df = pd.DataFrame(X_test, columns=['image_path'])
test_df['category_encoded'] = y_test.astype(str)

## 2.4 Configuraci贸n de Generadores de Datos para ResNet

train_df.head()

# %% Generadores de datos para ResNet
batch_size = 32
img_size = (224, 224)  # ResNet requiere 224x224

## 2.5 Aumentaci贸n de Datos para Entrenamiento (train_datagen)

# Data augmentation para entrenamiento
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Preprocesamiento espec铆fico de ResNet
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

## 2.6 Preprocesamiento para Validaci贸n y Prueba (test_datagen)

# Solo preprocesamiento para validaci贸n y prueba
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

## 2.7 Creaci贸n de los Flujos de Datos (flow_from_dataframe)

# Generador para el conjunto de entrenamiento
train_gen = train_datagen.flow_from_dataframe(
    train_df,                   # DataFrame con datos de entrenamiento (sobremuestreados)
    x_col='image_path',         # Columna con las rutas de las im谩genes
    y_col='category_encoded',   # Columna con las etiquetas codificadas (como string)
    target_size=img_size,       # Tama帽o al que se redimensionar谩n las im谩genes
    class_mode='binary',        # Para clasificaci贸n binaria
    color_mode='rgb',           # Cargar im谩genes en color
    shuffle=True,               # Mezclar los datos de entrenamiento en cada 茅poca
    batch_size=batch_size
)

# Generador para el conjunto de validaci贸n
valid_gen = test_datagen.flow_from_dataframe(
    valid_df,                   # DataFrame con datos de validaci贸n (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=True,               # Mezclar datos de validaci贸n (opcional, pero True en el script)
    batch_size=batch_size
)

# Generador para el conjunto de prueba
test_gen = test_datagen.flow_from_dataframe(
    test_df,                    # DataFrame con datos de prueba (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=False,              # IMPORTANTE: No mezclar el conjunto de prueba
    batch_size=batch_size
)



# Obtener un batch de datos del generador de entrenamiento
x_batch, y_batch = next(train_gen)

img_tensor = x_batch[0]
print('Forma de la imagen:', img_tensor.shape)
print('Tipo de dato de la imagen:', img_tensor.dtype)

np.printoptions(precision=2, suppress=True)
print('Valores de la imagen:')
print(img_tensor[:,:,0])# imagen del color rojo

# Bloque 3 : Entrenamiento_Modelo_ResNet50

## 3.1 Construcci贸n del Modelo ResNet50

# %% Construcci贸n del modelo ResNet50
def build_resnet_model(input_shape=(224, 224, 3)):
    # Cargar ResNet50 preentrenada (sin las capas superiores de clasificaci贸n de ImageNet)
    base_model = ResNet50(
        include_top=False,      # No incluir la capa densa final de ResNet50
        weights='imagenet',     # Usar pesos pre-entrenados en ImageNet
        input_shape=input_shape # Definir la forma de entrada de las im谩genes
    )

    # Congelar las capas del modelo base inicialmente.
    # Sus pesos no se actualizar谩n durante la primera fase de entrenamiento.
    base_model.trainable = False

    # Construir el modelo completo a帽adiendo nuestras propias capas encima de ResNet50
    inputs = layers.Input(shape=input_shape) # Capa de entrada
    # Pasar las entradas a trav茅s del modelo base.
    x = base_model(inputs, training=False)
    # Reducir la dimensionalidad espacial a un vector por cada mapa de caracter铆sticas.
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.5)(x)  # Capa de Dropout para regularizaci贸n
    # Capa densa final para la clasificaci贸n binaria, con activaci贸n sigmoide.
    # Se a帽ade regularizaci贸n L2 al kernel para prevenir el sobreajuste.
    outputs = layers.Dense(1, activation='sigmoid',
                          kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)

    # Crear el modelo final especificando las entradas y salidas.
    model = Model(inputs, outputs)
    return model

# Instanciar el modelo
model = build_resnet_model()

## 3.2 Compilaci贸n del Modelo

# Compilaci贸n del modelo
model.compile(
    optimizer=Adam(learning_rate=1e-3), # Optimizador Adam con una tasa de aprendizaje inicial
    loss='binary_crossentropy',         # Funci贸n de p茅rdida para clasificaci贸n binaria
    metrics=['accuracy', AUC(name='auc')] # M茅tricas a monitorear
)

## 3.3 Definici贸n de Callbacks

# Callbacks para el entrenamiento
callbacks_list = [
    callbacks.EarlyStopping(
        monitor='val_auc',        # M茅trica a monitorear (AUC en el conjunto de validaci贸n)
        patience=5,               # N煤mero de 茅pocas a esperar sin mejora antes de detener
        mode='max',               # Indica que buscamos maximizar la m茅trica (AUC)
        restore_best_weights=True,# Restaura los pesos del modelo de la mejor 茅poca al finalizar
        verbose=1                 # Muestra mensajes cuando el callback se activa
    ),
    callbacks.ReduceLROnPlateau(
        monitor='val_loss',       # M茅trica a monitorear (p茅rdida en el conjunto de validaci贸n)
        factor=0.1,               # Factor por el cual se reduce la tasa de aprendizaje (new_lr = lr * factor)
        patience=3,               # N煤mero de 茅pocas a esperar sin mejora antes de reducir LR
        verbose=1
    ),
    callbacks.ModelCheckpoint(
        'best_resnet_model.h5',   # Nombre del archivo para guardar el mejor modelo
        monitor='val_auc',        # M茅trica que determina si el modelo es "mejor"
        save_best_only=True,      # Guarda solo el modelo si la m茅trica monitoreada ha mejorado
        mode='max',               # El objetivo es maximizar val_auc
        verbose=1
    )
]

## 3.4 Entrenamiento en Dos Fases

### Fase 1: Entrenar Solo las Capas Nuevas (Clasificador Superior)

# Fase 1: Entrenar solo las capas nuevas
print("\nEntrenando capas nuevas...")
initial_epochs = 10 # N煤mero de 茅pocas para la primera fase de entrenamiento
history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=initial_epochs,
    callbacks=callbacks_list, # Utilizar la lista de callbacks definida
    verbose=1                 # Mostrar barra de progreso e informaci贸n por 茅poca
)

### Fase 2: Fine-Tuning de Todo el Modelo

# Fase 2: Fine-tuning de todo el modelo
print("\nFine-tuning de todo el modelo...")
# Acceder a la capa base ResNet50 dentro del modelo 'model'
base_model_layer_from_model = model.layers[1] # Obtenemos la referencia a la capa ResNet50
base_model_layer_from_model.trainable = True   # Hacemos que la capa ResNet50 sea entrenable

# Recompilar el modelo con una tasa de aprendizaje mucho m谩s baja para el fine-tuning
# Esto es esencial para no destruir los pesos pre-entrenados de ResNet50.
model.compile(
    optimizer=Adam(learning_rate=1e-5), # Tasa de aprendizaje significativamente menor
    loss='binary_crossentropy',
    metrics=['accuracy', AUC(name='auc')]
)

fine_tune_epochs = 10 # N煤mero de 茅pocas adicionales para el fine-tuning
total_epochs = initial_epochs + fine_tune_epochs # N煤mero total de 茅pocas de entrenamiento

# Continuar el entrenamiento (fine-tuning)
history_fine = model.fit(
    train_gen,
    validation_data=valid_gen,
    initial_epoch=history.epoch[-1]+1, # Comenzar el conteo de 茅pocas desde el final de la fase anterior
    epochs=total_epochs,            # Entrenar hasta alcanzar el n煤mero total de 茅pocas
    callbacks=callbacks_list,
    verbose=1
)

model.save('final_resnet_model.h5')

# Copiar el archivo .h5 al Drive
!cp final_resnet_model.h5 /content/drive/MyDrive/Brain_tumor_detection/final_resnet_model.h5

# Bloque 4 : Evaluaci贸n_del_Modelo.

## 4.1 Evaluaci贸n del Modelo en el Conjunto de Prueba

# %% Evaluaci贸n del modelo
def evaluate_model(model, test_gen):
    # Reiniciar el generador de prueba para asegurar que empieza desde el principio
    test_gen.reset()
    # Evaluar el modelo en el conjunto de prueba
    loss, accuracy, auc_score = model.evaluate(test_gen, verbose=0)

    print(f"\nResultados en conjunto de prueba:")
    print(f"P茅rdida (Loss): {loss:.4f}")
    print(f"Exactitud (Accuracy): {accuracy:.4f}")
    print(f"AUC: {auc_score:.4f}")

    # Obtener las probabilidades predichas por el modelo para el conjunto de prueba
    y_pred_probs = model.predict(test_gen)
    # Convertir las probabilidades a predicciones de clase (0 o 1) usando un umbral de 0.5
    y_pred = (y_pred_probs > 0.5).astype(int).flatten()
    # Obtener las etiquetas verdaderas del generador de prueba
    y_true = test_gen.classes

    # Obtener los nombres originales de las clases usando el label_encoder ajustado previamente
    class_names = list(label_encoder.inverse_transform([0, 1]))

    # --- Matriz de Confusi贸n ---
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Matriz de Confusi贸n - ResNet50')
    plt.ylabel('Etiqueta Verdadera')
    plt.xlabel('Etiqueta Predicha')
    plt.show()

    # --- Reporte de Clasificaci贸n ---
    print("\nReporte de Clasificaci贸n:")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # --- Curva ROC ---
    # Calcular la tasa de falsos positivos (fpr) y la tasa de verdaderos positivos (tpr)
    fpr, tpr, _ = roc_curve(y_true, y_pred_probs) # Usar y_pred_probs para la curva ROC
    # Calcular el rea Bajo la Curva ROC
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2,
             label=f'Curva ROC (谩rea = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # L铆nea de no discriminaci贸n
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Tasa de Falsos Positivos (FPR)')
    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
    plt.title('Curva ROC - ResNet50')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.show()

# Llamar a la funci贸n de evaluaci贸n con el modelo entrenado y el generador de prueba
evaluate_model(model, test_gen)

## 4.2 Visualizaci贸n del Historial de Entrenamiento

# %% Visualizaci贸n del historial de entrenamiento
def plot_combined_history(initial_hist, fine_tune_hist):
    # Extraer m茅tricas de la fase inicial
    acc = initial_hist.history['accuracy']
    val_acc = initial_hist.history['val_accuracy']
    loss = initial_hist.history['loss']
    val_loss = initial_hist.history['val_loss']

    # A帽adir m茅tricas de la fase de fine-tuning
    acc += fine_tune_hist.history['accuracy']
    val_acc += fine_tune_hist.history['val_accuracy']
    loss += fine_tune_hist.history['loss']
    val_loss += fine_tune_hist.history['val_loss']

    plt.figure(figsize=(12, 6))

    # Subgr谩fico para la Exactitud
    plt.subplot(1, 2, 1)
    plt.plot(acc, label='Exactitud de Entrenamiento')
    plt.plot(val_acc, label='Exactitud de Validaci贸n')
    # L铆nea vertical para marcar el inicio del fine-tuning
    # Asumiendo que initial_epochs fue definido como en el script original
    plt.plot([initial_epochs-1, initial_epochs-1],
             plt.ylim(), label='Inicio Fine-Tuning', linestyle='--')
    plt.title('Exactitud durante Entrenamiento')
    plt.xlabel('poca')
    plt.ylabel('Exactitud')
    plt.legend()
    plt.grid(True)

    # Subgr谩fico para la P茅rdida
    plt.subplot(1, 2, 2)
    plt.plot(loss, label='P茅rdida de Entrenamiento')
    plt.plot(val_loss, label='P茅rdida de Validaci贸n')
    # L铆nea vertical para marcar el inicio del fine-tuning
    plt.plot([initial_epochs-1, initial_epochs-1],
             plt.ylim(), label='Inicio Fine-Tuning', linestyle='--')
    plt.title('P茅rdida durante Entrenamiento')
    plt.xlabel('poca')
    plt.ylabel('P茅rdida')
    plt.legend()
    plt.grid(True)

    plt.tight_layout() # Ajustar el layout para evitar superposiciones
    plt.show()

# Llamar a la funci贸n para graficar el historial combinado
plot_combined_history(history, history_fine)
