# Bloque 1: Configuraci칩n Inicial y Carga de Datos 游늭

Comenzamos importando las herramientas necesarias. Aunque se utilizan varias librer칤as para el an치lisis, visualizaci칩n y m칠tricas, **TensorFlow** (junto con su API Keras) es el pilar para la construcci칩n y entrenamiento de nuestro modelo de Deep Learning. Tambi칠n se emplean librer칤as como Pandas para la manipulaci칩n de datos y OS para interactuar con el sistema de archivos.


##1.1 Importaci칩n de Librer칤as Esenciales

!python --version

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

# Librer칤as de Scikit-learn para preprocesamiento y m칠tricas
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc

# Imbalanced-learn para manejar desbalance de clases
#from imblearn.over_sampling import RandomOverSampler

# Componentes de TensorFlow y Keras
import tensorflow as tf
tf.get_logger().setLevel('ERROR')# Suprime mensajes informativos de TensorFlow, mostrando solo errores
tf.autograph.set_verbosity(0)
from tensorflow import keras
from keras import layers, Model, callbacks
from keras.api.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.api.applications import ResNet50 # El modelo base que usaremos
from keras.api.applications.resnet import preprocess_input # Funci칩n de preprocesamiento espec칤fica para ResNet
from keras.api.metrics import AUC # M칠trica de 츼rea Bajo la Curva ROC

# Configuraci칩n para la visualizaci칩n y logs de TensorFlow
sns.set_style("whitegrid") # Estilo para los gr치ficos de Seaborn


tf.__version__

from google.colab import drive
drive.mount('/content/drive')


## 1.2 Definici칩n de Rutas y Carga de Datos
Las im치genes se encuentran almacenadas en un directorio local, estructurado con subcarpetas que representan cada una de las clases (categor칤as) de nuestro problema de clasificaci칩n.
- **base_path:** Es el directorio ra칤z que contiene las subcarpetas de las categor칤as.
- **categories:** Una lista con los nombres de las subcarpetas, que corresponden a nuestras etiquetas de clase (ej. "Healthy", "Tumor").

base_path = "/content/drive/MyDrive/Brain_tumor_detection/image"  # Directorio ra칤z donde se encuentran las carpetas de categor칤as
categories = ["Healthy", "Tumor"] # Nombres de las subcarpetas y nuestras clases

image_paths = []  # Lista para almacenar las rutas a cada imagen
labels = []       # Lista para almacenar la etiqueta de cada imagen

# Iterar sobre cada categor칤a definida
for category in categories:
    category_path = os.path.join(base_path, category) # Construir la ruta a la carpeta de la categor칤a
    if os.path.isdir(category_path):
        # Iterar sobre cada archivo de imagen dentro de la carpeta de la categor칤a
        for image_name in os.listdir(category_path):
            image_path = os.path.join(category_path, image_name) # Ruta completa a la imagen
            image_paths.append(image_path) # A침adir la ruta de la imagen a la lista
            labels.append(category)        # A침adir la etiqueta (nombre de la categor칤a) a la lista
    else:
        print(f"Advertencia: El directorio para la categor칤a '{category}' no fue encontrado en '{category_path}'")


# Crear un DataFrame de Pandas para almacenar las rutas de las im치genes y sus etiquetas
df = pd.DataFrame({"image_path": image_paths, "label": labels})
# Mostrar las primeras filas del DataFrame y la distribuci칩n de clases
print("DataFrame inicial con rutas de im치genes y etiquetas:")
print(df.head())
print("\nDistribuci칩n de clases inicial:")
print(df['label'].value_counts())

# Bloque 2 : Preprocesamiento_de_Datos

## 2.1 Codificaci칩n de Etiquetas

# %% Preprocesamiento
# Codificaci칩n de etiquetas
label_encoder = LabelEncoder()
# Se crea una nueva columna 'category_encoded' con las etiquetas num칠ricas (ej. 0 para Healthy, 1 para Tumor)
df['category_encoded'] = label_encoder.fit_transform(df['label'])

print("DataFrame despu칠s de la codificaci칩n de etiquetas:")
print(df.head())
print(f"Clases codificadas: {label_encoder.classes_} -> {label_encoder.transform(label_encoder.classes_)}")

## 2.2 Divisi칩n de Datos

# Primero, dividir en entrenamiento (80%) y un conjunto temporal (20% para validaci칩n + prueba)
X_train_original, X_temp, y_train_original, y_temp = train_test_split(
    df[['image_path']],  # Caracter칤sticas (rutas de imagen como DataFrame)
    df['category_encoded'], # Etiquetas num칠ricas
    train_size=0.8,         # 80% para entrenamiento
    shuffle=True,           # Mezclar los datos antes de dividir
    random_state=42,        # Para reproducibilidad
    stratify=df['category_encoded'] # Asegurar proporciones de clase similares en la divisi칩n
)

# Luego, dividir el conjunto temporal en validaci칩n (50% de temp -> 10% del total)
X_valid, X_test, y_valid, y_test = train_test_split(
    X_temp,                 # DataFrame con rutas de imagen del conjunto temporal
    y_temp,                 # Etiquetas del conjunto temporal
    test_size=0.5,          # 50% de X_temp para el conjunto de prueba (el resto para validaci칩n)
    shuffle=True,
    random_state=42,
    stratify=y_temp         # Estratificar sobre las etiquetas del conjunto temporal
)

## 2.3 Creaci칩n de DataFrames para los Generadores

# train_df utilizar치 los datos de entrenamiento sobremuestreados.
train_df = pd.DataFrame(X_train_original, columns=['image_path'])
train_df['category_encoded'] = y_train_original.astype(str)

# valid_df y test_df utilizan los datos originales de validaci칩n y prueba, sin sobremuestreo.
valid_df = pd.DataFrame(X_valid, columns=['image_path'])
valid_df['category_encoded'] = y_valid.astype(str)

test_df = pd.DataFrame(X_test, columns=['image_path'])
test_df['category_encoded'] = y_test.astype(str)

## 2.4 Configuraci칩n de Generadores de Datos para ResNet

train_df.head()

# %% Generadores de datos para ResNet
batch_size = 32
img_size = (224, 224)  # ResNet requiere 224x224

## 2.5 Aumentaci칩n de Datos para Entrenamiento (train_datagen)

# Data augmentation para entrenamiento
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Preprocesamiento espec칤fico de ResNet
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

## 2.6 Preprocesamiento para Validaci칩n y Prueba (test_datagen)

# Solo preprocesamiento para validaci칩n y prueba
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

## 2.7 Creaci칩n de los Flujos de Datos (flow_from_dataframe)

# Generador para el conjunto de entrenamiento
train_gen = train_datagen.flow_from_dataframe(
    train_df,                   # DataFrame con datos de entrenamiento (sobremuestreados)
    x_col='image_path',         # Columna con las rutas de las im치genes
    y_col='category_encoded',   # Columna con las etiquetas codificadas (como string)
    target_size=img_size,       # Tama침o al que se redimensionar치n las im치genes
    class_mode='binary',        # Para clasificaci칩n binaria
    color_mode='rgb',           # Cargar im치genes en color
    shuffle=True,               # Mezclar los datos de entrenamiento en cada 칠poca
    batch_size=batch_size
)

# Generador para el conjunto de validaci칩n
valid_gen = test_datagen.flow_from_dataframe(
    valid_df,                   # DataFrame con datos de validaci칩n (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=True,               # Mezclar datos de validaci칩n (opcional, pero True en el script)
    batch_size=batch_size
)

# Generador para el conjunto de prueba
test_gen = test_datagen.flow_from_dataframe(
    test_df,                    # DataFrame con datos de prueba (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=False,              # IMPORTANTE: No mezclar el conjunto de prueba
    batch_size=batch_size
)



# Obtener un batch de datos del generador de entrenamiento
x_batch, y_batch = next(train_gen)

img_tensor = x_batch[0]
print('Forma de la imagen:', img_tensor.shape)
print('Tipo de dato de la imagen:', img_tensor.dtype)

np.printoptions(precision=2, suppress=True)
print('Valores de la imagen:')
print(img_tensor[:,:,0])# imagen del color rojo

# Bloque 3 : Entrenamiento_Modelo_ResNet50

## 3.1 Construcci칩n del Modelo ResNet50

# %% Construcci칩n del modelo ResNet50
def build_resnet_model(input_shape=(224, 224, 3)):
    # Cargar ResNet50 preentrenada (sin las capas superiores de clasificaci칩n de ImageNet)
    base_model = ResNet50(
        include_top=False,      # No incluir la capa densa final de ResNet50
        weights='imagenet',     # Usar pesos pre-entrenados en ImageNet
        input_shape=input_shape # Definir la forma de entrada de las im치genes
    )

    # Congelar las capas del modelo base inicialmente.
    # Sus pesos no se actualizar치n durante la primera fase de entrenamiento.
    base_model.trainable = False

    # Construir el modelo completo a침adiendo nuestras propias capas encima de ResNet50
    inputs = layers.Input(shape=input_shape) # Capa de entrada
    # Pasar las entradas a trav칠s del modelo base.
    x = base_model(inputs, training=False)
    # Reducir la dimensionalidad espacial a un vector por cada mapa de caracter칤sticas.
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.5)(x)  # Capa de Dropout para regularizaci칩n
    # Capa densa final para la clasificaci칩n binaria, con activaci칩n sigmoide.
    # Se a침ade regularizaci칩n L2 al kernel para prevenir el sobreajuste.
    outputs = layers.Dense(1, activation='sigmoid',
                          kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)

    # Crear el modelo final especificando las entradas y salidas.
    model = Model(inputs, outputs)
    return model

# Instanciar el modelo
model = build_resnet_model()

## 3.2 Compilaci칩n del Modelo

# Compilaci칩n del modelo
model.compile(
    optimizer=Adam(learning_rate=1e-3), # Optimizador Adam con una tasa de aprendizaje inicial
    loss='binary_crossentropy',         # Funci칩n de p칠rdida para clasificaci칩n binaria
    metrics=['accuracy', AUC(name='auc')] # M칠tricas a monitorear
)

## 3.3 Definici칩n de Callbacks

# Callbacks para el entrenamiento
callbacks_list = [
    callbacks.EarlyStopping(
        monitor='val_auc',        # M칠trica a monitorear (AUC en el conjunto de validaci칩n)
        patience=5,               # N칰mero de 칠pocas a esperar sin mejora antes de detener
        mode='max',               # Indica que buscamos maximizar la m칠trica (AUC)
        restore_best_weights=True,# Restaura los pesos del modelo de la mejor 칠poca al finalizar
        verbose=1                 # Muestra mensajes cuando el callback se activa
    ),
    callbacks.ReduceLROnPlateau(
        monitor='val_loss',       # M칠trica a monitorear (p칠rdida en el conjunto de validaci칩n)
        factor=0.1,               # Factor por el cual se reduce la tasa de aprendizaje (new_lr = lr * factor)
        patience=3,               # N칰mero de 칠pocas a esperar sin mejora antes de reducir LR
        verbose=1
    ),
    callbacks.ModelCheckpoint(
        'best_resnet_model.h5',   # Nombre del archivo para guardar el mejor modelo
        monitor='val_auc',        # M칠trica que determina si el modelo es "mejor"
        save_best_only=True,      # Guarda solo el modelo si la m칠trica monitoreada ha mejorado
        mode='max',               # El objetivo es maximizar val_auc
        verbose=1
    )
]

## 3.4 Entrenamiento en Dos Fases

### Fase 1: Entrenar Solo las Capas Nuevas (Clasificador Superior)

# Fase 1: Entrenar solo las capas nuevas
print("\nEntrenando capas nuevas...")
initial_epochs = 10 # N칰mero de 칠pocas para la primera fase de entrenamiento
history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=initial_epochs,
    callbacks=callbacks_list, # Utilizar la lista de callbacks definida
    verbose=1                 # Mostrar barra de progreso e informaci칩n por 칠poca
)

### Fase 2: Fine-Tuning de Todo el Modelo

# Fase 2: Fine-tuning de todo el modelo
print("\nFine-tuning de todo el modelo...")
# Acceder a la capa base ResNet50 dentro del modelo 'model'
base_model_layer_from_model = model.layers[1] # Obtenemos la referencia a la capa ResNet50
base_model_layer_from_model.trainable = True   # Hacemos que la capa ResNet50 sea entrenable

# Recompilar el modelo con una tasa de aprendizaje mucho m치s baja para el fine-tuning
# Esto es esencial para no destruir los pesos pre-entrenados de ResNet50.
model.compile(
    optimizer=Adam(learning_rate=1e-5), # Tasa de aprendizaje significativamente menor
    loss='binary_crossentropy',
    metrics=['accuracy', AUC(name='auc')]
)

fine_tune_epochs = 10 # N칰mero de 칠pocas adicionales para el fine-tuning
total_epochs = initial_epochs + fine_tune_epochs # N칰mero total de 칠pocas de entrenamiento

# Continuar el entrenamiento (fine-tuning)
history_fine = model.fit(
    train_gen,
    validation_data=valid_gen,
    initial_epoch=history.epoch[-1]+1, # Comenzar el conteo de 칠pocas desde el final de la fase anterior
    epochs=total_epochs,            # Entrenar hasta alcanzar el n칰mero total de 칠pocas
    callbacks=callbacks_list,
    verbose=1
)

model.save('final_resnet_model.h5')

# Copiar el archivo .h5 al Drive
!cp final_resnet_model.h5 /content/drive/MyDrive/Brain_tumor_detection/final_resnet_model.h5

# Bloque 4 : Evaluaci칩n_del_Modelo.

## 4.1 Evaluaci칩n del Modelo en el Conjunto de Prueba

# %% Evaluaci칩n del modelo
def evaluate_model(model, test_gen):
    # Reiniciar el generador de prueba para asegurar que empieza desde el principio
    test_gen.reset()
    # Evaluar el modelo en el conjunto de prueba
    loss, accuracy, auc_score = model.evaluate(test_gen, verbose=0)

    print(f"\nResultados en conjunto de prueba:")
    print(f"P칠rdida (Loss): {loss:.4f}")
    print(f"Exactitud (Accuracy): {accuracy:.4f}")
    print(f"AUC: {auc_score:.4f}")

    # Obtener las probabilidades predichas por el modelo para el conjunto de prueba
    y_pred_probs = model.predict(test_gen)
    # Convertir las probabilidades a predicciones de clase (0 o 1) usando un umbral de 0.5
    y_pred = (y_pred_probs > 0.5).astype(int).flatten()
    # Obtener las etiquetas verdaderas del generador de prueba
    y_true = test_gen.classes

    # Obtener los nombres originales de las clases usando el label_encoder ajustado previamente
    class_names = list(label_encoder.inverse_transform([0, 1]))

    # --- Matriz de Confusi칩n ---
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Matriz de Confusi칩n - ResNet50')
    plt.ylabel('Etiqueta Verdadera')
    plt.xlabel('Etiqueta Predicha')
    plt.show()

    # --- Reporte de Clasificaci칩n ---
    print("\nReporte de Clasificaci칩n:")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # --- Curva ROC ---
    # Calcular la tasa de falsos positivos (fpr) y la tasa de verdaderos positivos (tpr)
    fpr, tpr, _ = roc_curve(y_true, y_pred_probs) # Usar y_pred_probs para la curva ROC
    # Calcular el 츼rea Bajo la Curva ROC
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2,
             label=f'Curva ROC (치rea = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # L칤nea de no discriminaci칩n
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Tasa de Falsos Positivos (FPR)')
    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
    plt.title('Curva ROC - ResNet50')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.show()

# Llamar a la funci칩n de evaluaci칩n con el modelo entrenado y el generador de prueba
evaluate_model(model, test_gen)

## 4.2 Visualizaci칩n del Historial de Entrenamiento

# %% Visualizaci칩n del historial de entrenamiento
def plot_combined_history(initial_hist, fine_tune_hist):
    # Extraer m칠tricas de la fase inicial
    acc = initial_hist.history['accuracy']
    val_acc = initial_hist.history['val_accuracy']
    loss = initial_hist.history['loss']
    val_loss = initial_hist.history['val_loss']

    # A침adir m칠tricas de la fase de fine-tuning
    acc += fine_tune_hist.history['accuracy']
    val_acc += fine_tune_hist.history['val_accuracy']
    loss += fine_tune_hist.history['loss']
    val_loss += fine_tune_hist.history['val_loss']

    plt.figure(figsize=(12, 6))

    # Subgr치fico para la Exactitud
    plt.subplot(1, 2, 1)
    plt.plot(acc, label='Exactitud de Entrenamiento')
    plt.plot(val_acc, label='Exactitud de Validaci칩n')
    # L칤nea vertical para marcar el inicio del fine-tuning
    # Asumiendo que initial_epochs fue definido como en el script original
    plt.plot([initial_epochs-1, initial_epochs-1],
             plt.ylim(), label='Inicio Fine-Tuning', linestyle='--')
    plt.title('Exactitud durante Entrenamiento')
    plt.xlabel('칄poca')
    plt.ylabel('Exactitud')
    plt.legend()
    plt.grid(True)

    # Subgr치fico para la P칠rdida
    plt.subplot(1, 2, 2)
    plt.plot(loss, label='P칠rdida de Entrenamiento')
    plt.plot(val_loss, label='P칠rdida de Validaci칩n')
    # L칤nea vertical para marcar el inicio del fine-tuning
    plt.plot([initial_epochs-1, initial_epochs-1],
             plt.ylim(), label='Inicio Fine-Tuning', linestyle='--')
    plt.title('P칠rdida durante Entrenamiento')
    plt.xlabel('칄poca')
    plt.ylabel('P칠rdida')
    plt.legend()
    plt.grid(True)

    plt.tight_layout() # Ajustar el layout para evitar superposiciones
    plt.show()

# Llamar a la funci칩n para graficar el historial combinado
plot_combined_history(history, history_fine)
